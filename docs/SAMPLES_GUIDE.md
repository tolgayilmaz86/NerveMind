# NerveMind Sample Workflows

This directory contains sample workflow JSON files that demonstrate various features of NerveMind. Each sample is designed to teach specific workflow patterns and node types.

---

## ğŸ“‹ Table of Contents

1. [Available Samples](#available-samples)
2. [How to Import](#how-to-import)
3. [Viewing Workflow Output](#viewing-workflow-output)
4. [Prerequisites](#prerequisites)
5. [Workflow Details](#workflow-details)
   - [00 - Weather Alert (No Key)](#00---weather-alert-no-key)
   - [01 - Weather Alert Workflow](#01---weather-alert-workflow)
   - [02 - AI Content Generator](#02---ai-content-generator)
   - [03 - Data Processing Pipeline](#03---data-processing-pipeline)
   - [04 - Multi-API Integration](#04---multi-api-integration)
   - [05 - Error Handling Demo](#05---error-handling-demo)
   - [06 - File Watcher Workflow](#06---file-watcher-workflow)
   - [07 - iRacing Setup Advisor](#07---iracing-setup-advisor)
   - [08 - Gemini AI Assistant](#08---gemini-ai-assistant)
6. [Node Reference](#node-reference)
7. [Creating Your Own Workflows](#creating-your-own-workflows)
8. [Troubleshooting](#troubleshooting)

---

## Available Samples

| # | Workflow | Description | Difficulty | Features Demonstrated |
|---|----------|-------------|------------|----------------------|
| 00 | [Weather Alert (No Key)](00-weather-alert-workflow-no-apikey.json) | Zero-setup weather checking | â­ Beginner | HTTP Request (No Key), Open-Meteo |
| 01 | [Weather Alert](01-weather-alert-workflow.json) | Fetches weather data and sends alerts based on temperature | â­ Beginner | HTTP Request, Code, IF Conditional |
| 02 | [AI Content Generator](02-ai-content-generator.json) | Uses LLM to generate and validate content | â­â­ Intermediate | LLM Chat, Code, Chained AI Calls |
| 03 | [Data Processing Pipeline](03-data-processing-pipeline.json) | Processes item lists with filtering and aggregation | â­â­â­ Advanced | Loop, Merge, Data Aggregation |
| 04 | [Multi-API Integration](04-multi-api-integration.json) | Chains multiple APIs with AI enrichment | â­â­ Intermediate | Multiple HTTP, Data Chaining, LLM |
| 05 | [Error Handling Demo](05-error-handling-demo.json) | Demonstrates retry logic and fallback patterns | â­â­â­ Advanced | Retry Loops, Fallback, State Management |
| 06 | [File Watcher](06-file-watcher-workflow.json) | Monitors folders for file changes | â­â­ Intermediate | File Trigger, File Categorization |
| 07 | [iRacing Setup Advisor](07-iracing-setup-advisor.json) | Connect handling issues to get AI setup recommendations | â­â­ Intermediate | Selective Connections, Merge, LLM Advice |
| 08 | [Gemini AI Assistant](08-gemini-ai-assistant.json) | Summarize and analyze text using Google Gemini | â­ Beginner | Gemini 1.5 Flash, Prompt Chaining |
| 09 | [Local Knowledge Base (RAG)](09-local-knowledge-base-rag.json) | Q&A chatbot with local documents using RAG | â­â­ Intermediate | RAG, Embedding, Code, Privacy-focused AI |
| 10 | [Support Ticket Router](10-support-ticket-router.json) | AI-powered triage and routing for support tickets | â­â­ Intermediate | Webhook, Text Classifier, Switch, Routing |
| 11 | [System Health Monitor](11-system-health-monitor.json) | Daily automated health checks with parallel execution | â­â­â­ Advanced | Schedule, Parallel, Execute Command, Filter |
| 12 | [Resilient Data Scraper](12-resilient-data-scraper.json) | Bulletproof data fetching with retry and rate limiting | â­â­â­ Advanced | Retry, Rate Limit, Loop, Sort, Try/Catch |

### Node Coverage

The sample collection covers **all built-in node types**:

| Category | Nodes Covered | Samples |
|----------|---------------|---------|
| **Triggers** | Manual, Schedule, Webhook | 00-12 |
| **Actions** | HTTP Request, Code, Execute Command | 00-12 |
| **Flow** | If, Switch, Merge, Loop | 01, 03, 07, 10, 11, 12 |
| **Data** | Set, Filter, Sort | 01, 03, 11, 12 |
| **AI** | LLM Chat, Text Classifier, Embedding, RAG | 02, 04, 08, 09, 10 |
| **Advanced** | Subworkflow, Parallel, Try/Catch, Retry, Rate Limit | 05, 11, 12 |

---

## How to Import

```mermaid
flowchart LR
    A["ğŸ–¥ï¸ Open NerveMind"] --> B["ğŸ“ File Menu"]
    B --> C["ğŸ“¥ Import Workflow<br/><kbd>Ctrl+I</kbd>"]
    C --> D["ğŸ“„ Select .json file"]
    D --> E["âœ… Workflow Loaded"]
    
    style A fill:#e3f2fd,stroke:#1565c0
    style E fill:#c8e6c9,stroke:#2e7d32
```

1. Open NerveMind
2. Go to **File** > **Import Workflow** (or use `Ctrl+I`)
3. Select a `.json` file from this directory
4. The workflow will appear in your canvas

---

## Viewing Workflow Output

When you run a workflow, the **Execution Console** displays all outputs in real-time.

### Opening the Execution Console

```mermaid
flowchart LR
    A["â–¶ï¸ Run Workflow"] --> B["ğŸ“Š Console Opens<br/>Automatically"]
    B --> C["ğŸ“‹ View Node<br/>Outputs"]
    
    ALT["Or: View Menu"] --> D["ğŸ“Š Execution Console<br/><kbd>Ctrl+Shift+E</kbd>"]
    
    style B fill:#e3f2fd,stroke:#1565c0
    style C fill:#c8e6c9,stroke:#2e7d32
```

### Console Features

| Feature | Description |
|---------|-------------|
| **Hierarchical View** | Expand workflow â†’ execution â†’ nodes to drill down |
| **Node Outputs** | Click any node to see its input/output data |
| **Real-time Updates** | Watch data flow through nodes as they execute |
| **Filter by Status** | Show only errors, warnings, or all entries |
| **Search** | Find specific text in outputs |
| **Export** | Copy or export execution logs |

### What You'll See

```
ğŸ“‚ Weather Alert Workflow
  â””â”€â”€ ğŸ”„ Execution #1 (2:34:15 PM)
       â”œâ”€â”€ âœ… Manual Start
       â”‚    â””â”€â”€ Output: {}
       â”œâ”€â”€ âœ… Get Weather Data  
       â”‚    â””â”€â”€ Output: { body: "...", statusCode: 200 }
       â”œâ”€â”€ âœ… Extract Temperature
       â”‚    â””â”€â”€ Output: { temperature: 28, city: "London", ... }
       â”œâ”€â”€ âœ… Temperature > 25Â°C? â†’ TRUE
       â”œâ”€â”€ âœ… Format Hot Alert
       â”‚    â””â”€â”€ Output: { alertType: "HOT_WEATHER", message: "ğŸ”¥..." }
       â””â”€â”€ âœ… Final Output
            â””â”€â”€ Output: { result: "ğŸ”¥ Hot Weather Alert!...", ... }
```

### Output Locations

| Output Type | Where to Find It |
|-------------|------------------|
| **Node Output** | Click node in console â†’ "Output" tab |
| **Final Result** | Last node's output in the execution tree |
| **Errors** | Red âŒ icon on failed nodes with error details |
| **Logs** | "Logs" tab shows detailed execution trace |
| **Variables** | "Context" tab shows all workflow variables |

### Tips for Viewing Output

| Tip | Description |
|-----|-------------|
| ğŸ” **Expand JSON** | Click the expand icon to see formatted JSON |
| ğŸ“‹ **Copy Output** | Right-click â†’ Copy to clipboard |
| ğŸ”„ **Compare Runs** | Previous executions remain in console history |
| ğŸ“Œ **Pin Important** | Pin executions to keep them visible |
| ğŸ¯ **Click Node on Canvas** | Highlights corresponding console entry |

---

## Prerequisites

### API Keys Required

```mermaid
graph TD
    subgraph "ğŸ” Credential Options"
        A["Option 1:<br/>Global Settings"] 
        B["Option 2:<br/>Credential Manager<br/>(Recommended)"]
        C["Option 3:<br/>.env File Import"]
    end
    
    A --> D["âš¡ Quick Setup"]
    B --> E["ğŸ”’ Secure & Portable"]
    C --> F["ğŸ‘¥ Team Sharing"]
    
    style B fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px
```

| API Service | Used By Workflows | Get Key From |
|-------------|-------------------|--------------|
| OpenAI (GPT) | 02, 04 | [OpenAI Platform](https://platform.openai.com/api-keys) |
| OpenWeatherMap | 01, 04 | [OpenWeatherMap](https://openweathermap.org/api) |
| Anthropic (Claude) | Optional alternative | [Anthropic Console](https://console.anthropic.com/) |

#### Recommended: Credential Manager

1. Open **Tools** > **Credential Manager**
2. Click **Add Credential**
3. Create credentials:
   - **Name**: `openai-api` or `weather-api`
   - **Type**: `API_KEY`
   - **Data**: Your actual API key

---

## Workflow Details

---

### 01 - Weather Alert Workflow

> **Use Case:** Automated weather monitoring with conditional alerts

#### Workflow Diagram

```mermaid
flowchart LR
    subgraph TRIGGER ["ğŸŸ¢ Trigger"]
        T1["â¯ï¸ Manual Start"]
    end
    
    subgraph FETCH ["ğŸ“¡ Data Fetch"]
        H1["ğŸŒ HTTP Request<br/><i>Get Weather Data</i>"]
    end
    
    subgraph PROCESS ["âš™ï¸ Processing"]
        C1["ğŸ“ Code<br/><i>Extract Temperature</i>"]
        IF1{"â“ IF<br/><i>Temp > 25Â°C?</i>"}
    end
    
    subgraph BRANCHES ["ğŸ”€ Conditional Branches"]
        HOT["ğŸ”¥ Code<br/><i>Format Hot Alert</i>"]
        NORMAL["âœ… Code<br/><i>Format Normal Status</i>"]
    end
    
    subgraph OUTPUT ["ğŸ“¤ Output"]
        SET1["ğŸ“‹ Set<br/><i>Final Output</i>"]
    end
    
    T1 --> H1
    H1 --> C1
    C1 --> IF1
    IF1 -->|"TRUE"| HOT
    IF1 -->|"FALSE"| NORMAL
    HOT --> SET1
    NORMAL --> SET1
    
    style T1 fill:#a5d6a7,stroke:#2e7d32
    style IF1 fill:#fff9c4,stroke:#f9a825
    style HOT fill:#ffcdd2,stroke:#c62828
    style NORMAL fill:#c8e6c9,stroke:#2e7d32
```

#### Node Details

| Node | Type | Purpose | Input | Output |
|------|------|---------|-------|--------|
| **Manual Start** | `manualTrigger` | Initiates workflow execution | None | `{}` (empty trigger) |
| **Get Weather Data** | `httpRequest` | Fetches weather from OpenWeatherMap API | Trigger signal | `{ body: "JSON string", statusCode: 200 }` |
| **Extract Temperature** | `code` | Parses JSON and extracts weather fields | `{ body }` | `{ temperature, city, condition, threshold }` |
| **Temperature > 25Â°C?** | `if` | Evaluates temperature against threshold | `{ temperature, threshold }` | Routes to TRUE or FALSE branch |
| **Format Hot Alert** | `code` | Creates hot weather warning message | `{ city, temperature, condition }` | `{ alertType: "HOT_WEATHER", message, severity }` |
| **Format Normal Status** | `code` | Creates normal status message | `{ city, temperature, condition }` | `{ alertType: "NORMAL", message, severity }` |
| **Final Output** | `set` | Consolidates results | Alert data | `{ result, alertType, processedAt }` |

#### Data Flow Example

```mermaid
flowchart TD
    subgraph HTTP_RESPONSE ["HTTP Response"]
        R1["body: JSON string<br/>statusCode: 200"]
    end
    
    subgraph PARSED ["After Parse"]
        R2["temperature: 28<br/>city: London<br/>condition: Clouds<br/>threshold: 25"]
    end
    
    subgraph FINAL ["Final Output"]
        R3["alertType: HOT_WEATHER<br/>message: Hot Weather Alert<br/>severity: warning"]
    end
    
    R1 --> R2 --> R3
    
    style R1 fill:#e3f2fd,stroke:#1565c0
    style R2 fill:#fff9c4,stroke:#f9a825
    style R3 fill:#ffcdd2,stroke:#c62828
```

#### To Test

1. Create credential `weather-api` with your OpenWeatherMap API key
2. Update URL city parameter (default: London)
3. Run workflow
4. Check console for weather alert or normal status

---

### 02 - AI Content Generator

> **Use Case:** Automated content creation with AI validation

#### Workflow Diagram

```mermaid
flowchart LR
    subgraph TRIGGER ["ğŸŸ¢ Trigger"]
        T1["â¯ï¸ Manual Start"]
    end
    
    subgraph CONFIG ["ğŸ“ Configuration"]
        S1["ğŸ“‹ Set<br/><i>Set Topic</i>"]
    end
    
    subgraph AI_CHAIN ["ğŸ¤– AI Processing Chain"]
        L1["ğŸ§  LLM Chat<br/><i>Generate Outline</i>"]
        L2["ğŸ§  LLM Chat<br/><i>Write Content</i>"]
    end
    
    subgraph VALIDATE ["âœ”ï¸ Validation"]
        C1["ğŸ“ Code<br/><i>Format & Validate</i>"]
        IF1{"â“ IF<br/><i>Content Valid?</i>"}
    end
    
    subgraph RESULTS ["ğŸ“¤ Results"]
        SUCCESS["âœ… Code<br/><i>Prepare Output</i>"]
        ERROR["âŒ Code<br/><i>Handle Error</i>"]
    end
    
    T1 --> S1
    S1 --> L1
    L1 --> L2
    L2 --> C1
    C1 --> IF1
    IF1 -->|"TRUE"| SUCCESS
    IF1 -->|"FALSE"| ERROR
    
    style L1 fill:#e1bee7,stroke:#7b1fa2
    style L2 fill:#e1bee7,stroke:#7b1fa2
    style SUCCESS fill:#c8e6c9,stroke:#2e7d32
    style ERROR fill:#ffcdd2,stroke:#c62828
```

#### Node Details

| Node | Type | Purpose | Input | Output |
|------|------|---------|-------|--------|
| **Start Generation** | `manualTrigger` | Initiates workflow | None | `{}` |
| **Set Topic** | `set` | Configures generation parameters | Trigger | `{ topic, style, maxWords }` |
| **Generate Outline** | `llmChat` | Creates content outline with AI | `{ topic, style, maxWords }` | `{ response: "1. Point one\n2. Point two..." }` |
| **Write Content** | `llmChat` | Writes full article based on outline | `{ topic, style, maxWords, response }` | `{ response: "Full article text..." }` |
| **Format & Validate** | `code` | Validates and adds metadata | `{ response, topic, style }` | `{ title, content, metadata, validation }` |
| **Content Valid?** | `if` | Checks validation status | `{ validation.isValid }` | Routes to SUCCESS or ERROR |
| **Prepare Output** | `code` | Formats successful result | Content data | `{ status: "SUCCESS", article, message }` |
| **Handle Error** | `code` | Handles validation failure | Content data | `{ status: "VALIDATION_FAILED", error }` |

#### AI Chain Pattern

```mermaid
sequenceDiagram
    participant User
    participant Set as Set Topic
    participant LLM1 as LLM: Outline
    participant LLM2 as LLM: Content
    participant Code as Validator
    
    User->>Set: Start workflow
    Set->>LLM1: topic, style, maxWords
    LLM1->>LLM2: outline + original params
    Note over LLM1,LLM2: Chain passes context forward
    LLM2->>Code: full content
    Code->>User: validated article
```

#### To Test

1. Configure OpenAI API key in **Settings** > **AI Providers**
2. Modify the topic in "Set Topic" node
3. Run workflow
4. View generated content in console

---

### 03 - Data Processing Pipeline

> **Use Case:** Batch processing with filtering, transformation, and aggregation

#### Workflow Diagram

```mermaid
flowchart TB
    subgraph TRIGGER ["ğŸŸ¢ Start"]
        T1["â¯ï¸ Start Pipeline"]
    end
    
    subgraph DATA ["ğŸ“Š Data Setup"]
        S1["ğŸ“‹ Set<br/><i>Sample Data</i><br/>(7 products)"]
    end
    
    subgraph LOOP ["ğŸ” Loop Processing"]
        LP["ğŸ”„ Loop<br/><i>Process Each Product</i>"]
        
        subgraph FILTERS ["ğŸ” Filters"]
            IF1{"â“ In Stock?"}
            IF2{"â“ Above Min<br/>Price?"}
        end
        
        subgraph TRANSFORM ["âš™ï¸ Transform"]
            CODE1["ğŸ“ Apply<br/>Discount"]
            CODE2["ğŸ“ Mark<br/>Skipped"]
        end
    end
    
    subgraph COLLECT ["ğŸ“¥ Collect"]
        MG["ğŸ”€ Merge<br/><i>Collect Results</i>"]
    end
    
    subgraph AGGREGATE ["ğŸ“ˆ Aggregate"]
        AGG["ğŸ“ Code<br/><i>Aggregate Results</i>"]
    end
    
    T1 --> S1
    S1 --> LP
    LP --> IF1
    IF1 -->|"TRUE"| IF2
    IF1 -->|"FALSE"| CODE2
    IF2 -->|"TRUE"| CODE1
    IF2 -->|"FALSE"| CODE2
    CODE1 --> MG
    CODE2 --> MG
    MG --> AGG
    
    style LP fill:#bbdefb,stroke:#1565c0
    style IF1 fill:#fff9c4,stroke:#f9a825
    style IF2 fill:#fff9c4,stroke:#f9a825
    style CODE1 fill:#c8e6c9,stroke:#2e7d32
    style AGG fill:#e1bee7,stroke:#7b1fa2
```

#### Node Details

| Node | Type | Purpose | Input | Output |
|------|------|---------|-------|--------|
| **Start Pipeline** | `manualTrigger` | Initiates pipeline | None | `{}` |
| **Sample Data** | `set` | Provides product array | Trigger | `{ products[], discountPercent, minPrice }` |
| **Process Each Product** | `loop` | Iterates over products | `{ products }` | `{ item }` (one product per iteration) |
| **In Stock?** | `if` | Filters out-of-stock items | `{ item.inStock }` | Routes based on stock status |
| **Above Min Price?** | `if` | Filters low-price items | `{ item.price, minPrice }` | Routes based on price |
| **Apply Discount** | `code` | Calculates discounted price | `{ item, discountPercent }` | `{ ...item, finalPrice, processed: true }` |
| **Mark Skipped** | `code` | Marks ineligible items | `{ item }` | `{ ...item, skipped: true, skipReason }` |
| **Collect Results** | `merge` | Combines all results | Stream of items | Combined array |
| **Aggregate Results** | `code` | Calculates totals and groups | All items | `{ summary, processedItems, skippedItems, byCategory }` |

#### Data Transformation Example

```mermaid
flowchart LR
    subgraph "Input Products (7)"
        P1["Laptop $999 âœ“"]
        P2["Book $19 âœ“"]
        P3["Headphones $149 âœ—"]
        P4["Chair $299 âœ“"]
        P5["Monitor $449 âœ“"]
        P6["Notebook $9 âœ“"]
        P7["Keyboard $79 âœ—"]
    end
    
    subgraph "Filter: In Stock"
        F1["5 items pass"]
    end
    
    subgraph "Filter: Min Price $50"
        F2["3 items pass"]
    end
    
    subgraph "Output"
        O1["Processed: 3<br/>Skipped: 4<br/>Savings: $174.99"]
    end
    
    P1 & P2 & P3 & P4 & P5 & P6 & P7 --> F1
    F1 --> F2
    F2 --> O1
```

#### Output Structure

| Field | Type | Description |
|-------|------|-------------|
| `summary.totalProducts` | number | Total items processed |
| `summary.processedCount` | number | Items that received discount |
| `summary.skippedCount` | number | Items filtered out |
| `summary.totalOriginalPrice` | number | Sum before discounts |
| `summary.totalFinalPrice` | number | Sum after discounts |
| `summary.totalSavings` | number | Total discount amount |
| `processedItems` | array | Items with discount applied |
| `skippedItems` | array | Items that were filtered |
| `byCategory` | object | Items grouped by category |

#### To Test

1. No API keys needed - uses sample data
2. Modify the products array in "Sample Data" node
3. Adjust `discountPercent` and `minPrice` parameters
4. Run and view aggregated results

---

### 04 - Multi-API Integration

> **Use Case:** Combining multiple data sources with AI enhancement

#### Workflow Diagram

```mermaid
flowchart LR
    subgraph TRIGGER ["ğŸŸ¢ Trigger"]
        T1["â¯ï¸ Start"]
    end
    
    subgraph API1 ["ğŸ‘¤ User API"]
        H1["ğŸŒ HTTP<br/><i>Get Random User</i>"]
        C1["ğŸ“ Code<br/><i>Parse User Data</i>"]
    end
    
    subgraph API2 ["ğŸŒ¤ï¸ Weather API"]
        H2["ğŸŒ HTTP<br/><i>Get Location Weather</i>"]
        C2["ğŸ“ Code<br/><i>Parse Weather</i>"]
    end
    
    subgraph AI ["ğŸ¤– AI Enhancement"]
        L1["ğŸ§  LLM<br/><i>Generate Greeting</i>"]
    end
    
    subgraph OUTPUT ["ğŸ“¤ Output"]
        CF["ğŸ“ Code<br/><i>Build Final Profile</i>"]
    end
    
    T1 --> H1
    H1 --> C1
    C1 --> H2
    H2 --> C2
    C2 --> L1
    L1 --> CF
    
    style H1 fill:#bbdefb,stroke:#1565c0
    style H2 fill:#bbdefb,stroke:#1565c0
    style L1 fill:#e1bee7,stroke:#7b1fa2
```

#### Node Details

| Node | Type | Purpose | Input | Output |
|------|------|---------|-------|--------|
| **Start** | `manualTrigger` | Initiates workflow | None | `{}` |
| **Get Random User** | `httpRequest` | Fetches random user profile | Trigger | `{ body: "JSON" }` |
| **Parse User Data** | `code` | Extracts user info and location | HTTP response | `{ user, location: { city, lat, lon } }` |
| **Get Location Weather** | `httpRequest` | Fetches weather for user's location | `{ location.lat, location.lon }` | `{ body: "JSON" }` |
| **Parse Weather** | `code` | Combines user and weather data | HTTP response + user | `{ user, location, weather }` |
| **Generate Greeting** | `llmChat` | Creates personalized greeting | Combined data | `{ response: "greeting text" }` |
| **Build Final Profile** | `code` | Assembles enriched profile | All data | `{ profile, weather, personalizedGreeting }` |

#### API Chain Pattern

```mermaid
sequenceDiagram
    participant WF as Workflow
    participant RU as randomuser.me
    participant OW as openweathermap.org
    participant AI as OpenAI
    
    WF->>RU: GET /api/
    RU-->>WF: { user: { name, location } }
    Note over WF: Extract lat/lon
    WF->>OW: GET /weather?lat=X&lon=Y
    OW-->>WF: { temp, condition }
    Note over WF: Combine data
    WF->>AI: Generate greeting for user + weather
    AI-->>WF: "Hello John! It's sunny in Paris..."
    Note over WF: Build final profile
```

#### Output Structure

| Field | Example Value | Description |
|-------|---------------|-------------|
| `profile.name` | John Smith | User's full name |
| `profile.email` | john@example.com | User's email |
| `profile.location` | Paris, France | User's city and country |
| `weather.summary` | 22Â°C - clear sky | Weather description |
| `personalizedGreeting` | Bonjour John! ... | AI-generated greeting |
| `apisCalled` | 3 APIs | List of external services used |

#### To Test

1. Configure OpenAI API key in Settings
2. Get OpenWeatherMap API key
3. Run workflow
4. View enriched profile with AI greeting

---

### 05 - Error Handling Demo

> **Use Case:** Building robust workflows with retry and fallback patterns

#### Workflow Diagram

```mermaid
flowchart TB
    subgraph TRIGGER ["ğŸŸ¢ Start"]
        T1["â¯ï¸ Start"]
        S1["ğŸ“‹ Set<br/><i>Configuration</i>"]
    end
    
    subgraph TRY ["ğŸ”„ Try Block"]
        ATT["ğŸ“ Code<br/><i>Attempt Primary API</i>"]
        IF1{"â“ API<br/>Successful?"}
    end
    
    subgraph SUCCESS_PATH ["âœ… Success Path"]
        SUC["ğŸ“ Code<br/><i>Process Success</i>"]
    end
    
    subgraph RETRY_LOGIC ["ğŸ” Retry Logic"]
        CHK["ğŸ“ Code<br/><i>Check Retry Count</i>"]
        IF2{"â“ Retry<br/>Available?"}
        WAIT["â³ Code<br/><i>Wait & Increment</i>"]
    end
    
    subgraph FALLBACK ["ğŸ”€ Fallback"]
        FB["ğŸ“ Code<br/><i>Use Fallback API</i>"]
    end
    
    subgraph OUTPUT ["ğŸ“¤ Output"]
        MG["ğŸ”€ Merge"]
        RPT["ğŸ“ Code<br/><i>Generate Report</i>"]
    end
    
    T1 --> S1
    S1 --> ATT
    ATT --> IF1
    IF1 -->|"TRUE"| SUC
    IF1 -->|"FALSE"| CHK
    CHK --> IF2
    IF2 -->|"TRUE"| WAIT
    IF2 -->|"FALSE"| FB
    WAIT -->|"Retry"| ATT
    FB --> SUC
    SUC --> MG
    MG --> RPT
    
    style ATT fill:#fff9c4,stroke:#f9a825
    style IF2 fill:#fff9c4,stroke:#f9a825
    style FB fill:#ffcdd2,stroke:#c62828
    style SUC fill:#c8e6c9,stroke:#2e7d32
```

#### Node Details

| Node | Type | Purpose | Input | Output |
|------|------|---------|-------|--------|
| **Start** | `manualTrigger` | Initiates workflow | None | `{}` |
| **Configuration** | `set` | Sets retry parameters | Trigger | `{ maxRetries: 3, retryDelay, simulateError }` |
| **Attempt Primary API** | `code` | Simulates API call | Config | `{ success, data/error, attempt }` |
| **API Successful?** | `if` | Checks API success | `{ success }` | Routes to success or retry |
| **Check Retry Count** | `code` | Evaluates retry eligibility | `{ attempt, maxRetries }` | `{ shouldRetry, shouldUseFallback }` |
| **Retry Available?** | `if` | Checks if retries remain | `{ shouldRetry }` | Routes to retry or fallback |
| **Wait & Increment** | `code` | Increments attempt counter | `{ attempt }` | `{ attempt: N+1 }` (loops back) |
| **Use Fallback API** | `code` | Simulates fallback success | Error context | `{ success: true, source: "fallback" }` |
| **Process Success** | `code` | Handles successful response | Success data | `{ status: "SUCCESS", result, metadata }` |
| **Generate Report** | `code` | Creates execution report | All data | `{ report: { status, source, usedFallback } }` |

#### Retry Flow Visualization

```mermaid
stateDiagram-v2
    [*] --> Attempt1: Start
    Attempt1 --> Success: API OK
    Attempt1 --> Retry1: API Failed (1/3)
    
    Retry1 --> Attempt2: Wait
    Attempt2 --> Success: API OK
    Attempt2 --> Retry2: API Failed (2/3)
    
    Retry2 --> Attempt3: Wait
    Attempt3 --> Success: API OK
    Attempt3 --> Fallback: API Failed (3/3)
    
    Fallback --> Success: Fallback OK
    Success --> [*]: Complete
```

#### To Test

1. No API keys needed - uses simulated responses
2. Toggle `simulateError` in Configuration node:
   - `true` â†’ See retry/fallback path
   - `false` â†’ See success path
3. Adjust `maxRetries` to test different scenarios

---

### 06 - File Watcher Workflow

> **Use Case:** Automated file processing for local folders

#### Workflow Diagram

```mermaid
flowchart LR
    subgraph TRIGGER ["ğŸ“ File Trigger"]
        FT["ğŸ‘ï¸ File Trigger<br/><i>Watch Downloads</i>"]
    end
    
    subgraph PROCESS ["âš™ï¸ Processing"]
        C1["ğŸ“ Code<br/><i>Process File Info</i>"]
        IF1{"â“ IF<br/><i>Is Document?</i>"}
    end
    
    subgraph BRANCHES ["ğŸ”€ File Handlers"]
        DOC["ğŸ“„ Code<br/><i>Process Document</i>"]
        OTHER["ğŸ“ Code<br/><i>Log Other File</i>"]
    end
    
    subgraph OUTPUT ["ğŸ“¤ Output"]
        SET1["ğŸ“‹ Set<br/><i>Final Result</i>"]
    end
    
    FT -->|"File Event"| C1
    C1 --> IF1
    IF1 -->|"TRUE<br/>(pdf, doc, txt)"| DOC
    IF1 -->|"FALSE<br/>(other types)"| OTHER
    DOC --> SET1
    OTHER --> SET1
    
    style FT fill:#fff3e0,stroke:#ef6c00
    style DOC fill:#e3f2fd,stroke:#1565c0
    style OTHER fill:#f3e5f5,stroke:#7b1fa2
```

#### Node Details

| Node | Type | Purpose | Input | Output |
|------|------|---------|-------|--------|
| **Watch Downloads** | `fileTrigger` | Monitors folder for file events | File system events | `{ filePath, fileName, eventType, directory }` |
| **Process File Info** | `code` | Analyzes and categorizes file | File event | `{ fileName, extension, category, eventType }` |
| **Is Document?** | `if` | Checks if file is a document | `{ category }` | Routes based on category |
| **Process Document** | `code` | Handles document files | File info | `{ action: "DOCUMENT_PROCESSING", message }` |
| **Log Other File** | `code` | Logs non-document files | File info | `{ action: "FILE_LOGGED", message }` |
| **Final Result** | `set` | Consolidates result | Action data | `{ result, action, status, filePath }` |

#### File Categorization Logic

```mermaid
flowchart TD
    FILE["ğŸ“„ Incoming File"]
    
    FILE --> EXT{"Extension?"}
    
    EXT -->|"jpg, png, gif, webp"| IMG["ğŸ–¼ï¸ Image"]
    EXT -->|"pdf, doc, docx, txt"| DOC["ğŸ“„ Document"]
    EXT -->|"mp4, avi, mkv, mov"| VID["ğŸ¬ Video"]
    EXT -->|"mp3, wav, flac"| AUD["ğŸµ Audio"]
    EXT -->|"zip, rar, 7z, tar"| ARC["ğŸ“¦ Archive"]
    EXT -->|"other"| OTH["ğŸ“ Other"]
    
    style DOC fill:#e3f2fd,stroke:#1565c0
    style IMG fill:#fff3e0,stroke:#ef6c00
    style VID fill:#f3e5f5,stroke:#7b1fa2
```

#### File Trigger Configuration

| Parameter | Description | Example |
|-----------|-------------|---------|
| `watchPath` | Folder to monitor | `C:\Users\tolga\Downloads\test` |
| `eventTypes` | Events to capture | `CREATE,MODIFY,DELETE` |
| `filePattern` | File filter pattern | `*.pdf`, `*.txt`, `*` (all) |

#### To Test

1. Update `watchPath` to your target folder
2. Configure `eventTypes` and `filePattern`
3. Run the workflow (stays active)
4. Drop a file into the watched folder
5. Verify workflow processes the file

---

### 07 - iRacing Setup Advisor

> **Use Case:** Connect handling issue nodes that match your car's behavior to get AI-powered setup recommendations

#### Workflow Diagram

```mermaid
flowchart TB
    subgraph TRIGGER ["ğŸŸ¢ Start"]
        T1["â¯ï¸ Analyze My Setup"]
        CAR["ğŸï¸ Car & Track Info"]
    end
    
    subgraph ISSUES ["ğŸ¯ Handling Issues - Connect What Applies"]
        direction TB
        subgraph UNDERSTEER ["ğŸ”µ Understeer Issues"]
            US1["Slow Entry"]
            US2["Fast Entry"]
            US3["Mid-Corner"]
        end
        subgraph OVERSTEER ["ğŸ”´ Oversteer Issues"]
            OS1["Slow Entry"]
            OS2["Fast Entry"]
            OS3["Mid-Corner"]
            OS4["Exit/Power"]
        end
        subgraph OTHER ["âš ï¸ Other Issues"]
            OT1["Unstable Braking"]
            OT2["Low Traction"]
            OT3["Curb Instability"]
        end
    end
    
    subgraph PROCESS ["âš™ï¸ Processing"]
        MG["ğŸ”€ Collect Issues"]
        BUILD["ğŸ“ Build Analysis"]
        IF1{"Has Issues?"}
    end
    
    subgraph AI ["ğŸ¤– AI Advisor"]
        LLM["ğŸ§  Setup Advisor AI"]
        FMT["ğŸ“‹ Format Advice"]
    end
    
    subgraph OUTPUT ["ğŸ“¤ Results"]
        NO["âš ï¸ No Issues Message"]
        RESULT["ğŸ Setup Recommendations"]
    end
    
    T1 --> CAR
    CAR --> MG
    US1 -.->|"connect if applies"| MG
    US2 -.-> MG
    US3 -.-> MG
    OS1 -.-> MG
    OS2 -.-> MG
    OS3 -.-> MG
    OS4 -.->|"default connected"| MG
    OT1 -.-> MG
    OT2 -.-> MG
    OT3 -.-> MG
    MG --> BUILD
    BUILD --> IF1
    IF1 -->|"TRUE"| LLM
    IF1 -->|"FALSE"| NO
    LLM --> FMT
    FMT --> RESULT
    NO --> RESULT
    
    style US1 fill:#bbdefb,stroke:#1565c0
    style US2 fill:#bbdefb,stroke:#1565c0
    style US3 fill:#bbdefb,stroke:#1565c0
    style OS1 fill:#ffcdd2,stroke:#c62828
    style OS2 fill:#ffcdd2,stroke:#c62828
    style OS3 fill:#ffcdd2,stroke:#c62828
    style OS4 fill:#ffcdd2,stroke:#c62828
    style LLM fill:#e1bee7,stroke:#7b1fa2
```

#### Available Issue Nodes

| Node | Type | Description | When to Connect |
|------|------|-------------|-----------------|
| ğŸ”µ **Understeer: Slow Entry** | understeer | Car pushes wide entering hairpins/chicanes | Front washes out on tight corner turn-in |
| ğŸ”µ **Understeer: Fast Entry** | understeer | Front feels light at high-speed entries | Car won't rotate in fast sweepers |
| ğŸ”µ **Understeer: Mid-Corner** | understeer | Pushes wide through apex | Running wide while maintaining throttle |
| ğŸ”´ **Oversteer: Slow Entry** | oversteer | Rear steps out under trail braking | Snap oversteer into slow corners |
| ğŸ”´ **Oversteer: Fast Entry** | oversteer | Rear nervous at high speed | Need to catch slides in fast corners |
| ğŸ”´ **Oversteer: Mid-Corner** | oversteer | Car rotates too much mid-corner | Constant steering corrections needed |
| ğŸ”´ **Oversteer: Exit/Power** | oversteer | Rear breaks loose on throttle | Wheel spin, tank slappers on exit |
| âš ï¸ **Unstable Under Braking** | instability | Car wants to swap ends braking | Rear loose in braking zones |
| âš ï¸ **Low Overall Traction** | traction | General lack of grip | Sliding everywhere, tire overheat |
| âš ï¸ **Curb Instability** | instability | Car upset by kerbs/bumps | Bouncing, losing grip over curbs |

#### How to Use This Workflow

```mermaid
flowchart LR
    subgraph STEP1 ["Step 1: Configure"]
        A["Edit Car & Track Info node"]
    end
    
    subgraph STEP2 ["Step 2: Identify Issues"]
        B["Test drive your car"]
        C["Note handling problems"]
    end
    
    subgraph STEP3 ["Step 3: Connect Nodes"]
        D["Connect matching issue nodes"]
        E["Disconnect non-issues"]
    end
    
    subgraph STEP4 ["Step 4: Run"]
        F["Click Run"]
        G["Get AI recommendations"]
    end
    
    A --> B --> C --> D --> E --> F --> G
    
    style D fill:#fff9c4,stroke:#f9a825
    style G fill:#c8e6c9,stroke:#2e7d32
```

#### Node Details

| Node | Type | Purpose | Input | Output |
|------|------|---------|-------|--------|
| **Analyze My Setup** | `manualTrigger` | Starts the analysis | None | `{}` |
| **Car & Track Info** | `set` | Your car, track, conditions | Trigger | `{ car, track, conditions, ... }` |
| **Issue Nodes** (x10) | `set` | Describe specific handling problems | Trigger (connect to enable) | `{ issueType, cornerPhase, symptoms, ... }` |
| **Collect Issues** | `merge` | Aggregates connected issues | Car info + issues | Combined array |
| **Build Analysis** | `code` | Structures data for AI | Merged data | `{ car, track, issuesSummary, ... }` |
| **Has Issues?** | `if` | Checks if issues connected | `{ issueCount }` | Routes appropriately |
| **Setup Advisor AI** | `llmChat` | Generates recommendations | Analysis context | `{ response: "detailed advice" }` |
| **Format Advice** | `code` | Parses AI response into sections | AI response | `{ diagnosis, setupChanges, tips, warnings }` |
| **Final Output** | `merge` | Rejoins exclusive IF branches | Either branch | Pass-through with `waitForAll: false` |

#### Key Pattern: Exclusive Branch Merge

This workflow demonstrates the **exclusive branch merge pattern** - when an IF node creates two mutually exclusive paths (only one will ever execute), the merge node at the end uses `waitForAll: false` to proceed immediately with whichever branch fires:

```json
{
    "type": "merge",
    "parameters": {
        "mode": "passthrough",
        "waitForAll": false
    }
}
```

Without `waitForAll: false`, the merge node would wait indefinitely for the branch that never executes.

#### Example Output

When you connect "Understeer: Slow Entry" and "Oversteer: Exit/Power":

| Section | Example Content |
|---------|-----------------|
| **DIAGNOSIS** | The car has a classic "tight on entry, loose on exit" balance. The front lacks grip on turn-in at slow speeds, but the rear breaks loose when applying power. |
| **SETUP CHANGES** | 1. **Front ARB**: Soften 1-2 clicks - improves turn-in grip<br/>2. **Rear ARB**: Stiffen 1-2 clicks - stabilizes rear on power<br/>3. **Rear Wing**: Add 1-2 degrees - more rear downforce on exit<br/>4. **Diff Preload**: Reduce slightly - smoother power application<br/>5. **Rear Springs**: Stiffen 50-100 lbs - reduces squat on accel |
| **DRIVING TIPS** | Trail brake deeper to rotate the car. Apply throttle more gradually on exit. Use momentum through slow corners. |
| **WARNINGS** | Stiffening rear ARB may increase mid-corner oversteer. Adding rear wing affects top speed. |

#### Car Info Configuration

Edit the "Car & Track Info" node to match your setup:

| Parameter | Description | Example |
|-----------|-------------|---------|
| `car` | Your car model | Porsche 911 GT3 R |
| `track` | Current track | Spa-Francorchamps |
| `conditions` | Weather/temp | Dry, 25Â°C track temp |
| `currentSetup` | Setup baseline | Baseline with minor adjustments |
| `sessionType` | Race/Qualify/Practice | Race |
| `tireCompound` | Tire type | Medium |
| `fuelLoad` | Fuel level | Half tank |

#### To Test

1. Configure OpenAI API key in **Settings** > **AI Providers**
2. Edit "Car & Track Info" with your car/track
3. **Connect** the issue nodes that match your car's behavior to "Collect Issues"
4. **Disconnect** issue nodes that don't apply (default has 2 connected)
5. Run the workflow
6. View recommendations in the Execution Console

#### Default Connections

The workflow comes with two issues pre-connected as an example:
- ğŸ”µ Understeer: Slow Entry
- ğŸ”´ Oversteer: Exit/Power

Modify connections based on YOUR car's actual handling!

---

### 08 - Gemini AI Assistant

> **Use Case:** AI-powered text summarization and analysis using Google Gemini

#### Workflow Diagram

```mermaid
flowchart LR
    subgraph TRIGGER ["ğŸŸ¢ Trigger"]
        T1["â¯ï¸ Manual Start"]
    end
    
    subgraph AI_CHAIN ["ğŸ¤– AI Chain"]
        G1["ğŸ§  LLM Chat<br/><i>Summarize</i>"]
        G2["ğŸ§  LLM Chat<br/><i>Analyze</i>"]
    end
    
    subgraph OUTPUT ["ğŸ“¤ Output"]
        F1["ğŸ“ Code<br/><i>Format</i>"]
        RES["ğŸ“‹ Set<br/><i>Result</i>"]
    end
    
    T1 --> G1
    G1 --> G2
    G2 --> F1
    F1 --> RES
    
    style G1 fill:#e1bee7,stroke:#7b1fa2
    style G2 fill:#e1bee7,stroke:#7b1fa2
```

#### Node Details

| Node | Type | Purpose | Input | Output |
|------|------|---------|-------|--------|
| **Start** | `manualTrigger` | Provides sample text | None | `{ text, task }` |
| **Summarize Text** | `llmChat` | Summarizes input text (Gemini Flash) | `{ text }` | `{ response: "summary..." }` |
| **Analyze Content** | `llmChat` | Analyzes sentiment and entities | `{ text, response }` | `{ response: "analysis..." }` |
| **Format Output** | `code` | Structures the final result | All inputs | `{ result: { summary, analysis } }` |
| **Final Result** | `set` | Displays final output | Formatted data | `{ wordCount, summary, analysis }` |

#### Gemini Specifics

This workflow uses the **Google Gemini** provider (`google`). 
- **Model**: `gemini-1.5-flash` (Optimized for speed/cost)
- **Context**: Can handle large context windows (up to 1M tokens)

#### To Test

1. Get a **Google AI Studio Key** (`GOOGLE_API_KEY`) from consumers.google.com
2. Configure **Settings** > **AI Providers** > **Google Gemini**
3. Run workflow
4. Check console for summary and analysis

---

### 00 - Weather Alert (No API Key)

> **Use Case:** Identical to Sample 01, but uses a free API that requires **no key**.

#### Why This Exists?
If you don't have an OpenWeatherMap key yet, use this sample to test HTTP requests immediately. It connects to [Open-Meteo](https://open-meteo.com/), which is free for non-commercial use without an API key.

#### Workflow Diagram

```mermaid
flowchart LR
    T1["â¯ï¸ Start"] --> H1["ğŸŒ HTTP<br/><i>Open-Meteo</i>"]
    H1 --> C1["ğŸ“ Parse"] --> IF1{"â“ > 25Â°C?"}
    IF1 -->|Yes| HOT["ğŸ”¥ Hot Alert"]
    IF1 -->|No| OK["âœ… Normal"]
```

#### To Test
1. **Just Click Run!** No setup required.

---

## Node Reference

### Quick Reference Card

```mermaid
mindmap
  root((NerveMind<br/>Nodes))
    Triggers
      â¯ï¸ manualTrigger
      ğŸ‘ï¸ fileTrigger
      â° scheduleTrigger
      ğŸª webhookTrigger
    Data
      ğŸ“‹ set
      ğŸ“ code
      ğŸ”€ merge
    Control Flow
      â“ if
      ğŸ”„ loop
      â¹ï¸ stop
    External
      ğŸŒ httpRequest
      ğŸ§  llmChat
      ğŸ“§ sendEmail
```

### Node Input/Output Summary

| Node Type | Icon | Input | Output | Use Case |
|-----------|------|-------|--------|----------|
| `manualTrigger` | â¯ï¸ | None | `{}` | Start workflow manually |
| `fileTrigger` | ğŸ‘ï¸ | File system events | `{ filePath, fileName, eventType }` | Monitor folders |
| `set` | ğŸ“‹ | Any | Configured values | Set/transform variables |
| `code` | ğŸ“ | Any (`input` variable) | Return value | Custom logic |
| `httpRequest` | ğŸŒ | URL, headers, body | `{ body, statusCode, headers }` | Call APIs |
| `llmChat` | ğŸ§  | Prompts, context | `{ response }` | AI text generation |
| `if` | â“ | Condition expression | Routes to TRUE/FALSE | Branching logic |
| `loop` | ğŸ”„ | Array/items | `{ item, index }` per iteration | Iterate over data |
| `merge` | ğŸ”€ | Multiple inputs | Combined data | Collect parallel branches |

### Expression Syntax

| Pattern | Example | Description |
|---------|---------|-------------|
| `{{ variable }}` | `{{ statusCode }}` | Access variable |
| `{{ nested.path }}` | `{{ response.data.name }}` | Access nested property |
| `{{ arr[0] }}` | `{{ items[0].id }}` | Access array element |

---

## Creating Your Own Workflows

### Common Patterns

```mermaid
flowchart TB
    subgraph "Pattern 1: API Integration"
        A1["HTTP Request"] --> A2["Code: Parse"] --> A3["Process"]
    end
    
    subgraph "Pattern 2: Conditional Logic"
        B1["Data"] --> B2{"IF"} 
        B2 -->|T| B3["Branch A"]
        B2 -->|F| B4["Branch B"]
        B3 & B4 --> B5["Merge"]
    end
    
    subgraph "Pattern 3: AI Enhancement"
        C1["Data"] --> C2["LLM"] --> C3["Code: Format"]
    end
    
    subgraph "Pattern 4: Batch Processing"
        D1["Data"] --> D2["Loop"] --> D3["Process Each"] --> D4["Aggregate"]
    end
    
    subgraph "Pattern 5: Error Handling"
        E1["Try"] --> E2{"Success?"}
        E2 -->|Y| E3["Continue"]
        E2 -->|N| E4["Retry/Fallback"]
    end
```

### Best Practices

| Practice | Description |
|----------|-------------|
| âœ… Parse API responses immediately | Use Code node after HTTP to extract needed fields |
| âœ… Use meaningful node names | "Get Weather Data" > "HTTP Request" |
| âœ… Add notes to complex nodes | Explain the logic for future reference |
| âœ… Handle both IF branches | Always define TRUE and FALSE paths |
| âœ… Use Merge after parallel branches | Collect results before continuing |
| âœ… Test with simple data first | Validate logic before adding complexity |

---

## Troubleshooting

| Issue | Solution |
|-------|----------|
| "API key not found" | Configure in **Settings** > **AI Providers** or **Tools** > **Credential Manager** |
| "Credential not found" | Ensure credential exists and is selected in node |
| HTTP timeout | Increase timeout in node settings |
| "Node type not found" | Update to compatible NerveMind version |
| Empty LLM response | Check API key validity and credits |
| Loop not iterating | Ensure input is array: `{{ products }}` |
| IF always takes same branch | Check condition syntax and data types |
| File Trigger not firing | Verify `watchPath` exists and is accessible |

---

## Security Best Practices

| Practice | Description |
|----------|-------------|
| ğŸ”’ Use Credential Manager | Encrypts API keys securely |
| ğŸš« Never commit API keys | Keep keys out of version control |
| ğŸ”„ Rotate keys regularly | Update credentials periodically |
| ğŸ‘¥ Use separate credentials | Different keys for dev/staging/prod |
| ğŸ“ Use .env for teams | Gitignore and import securely |

---

*For more information, see the [Architecture Guide](../docs/ARCHITECTURE.md)*
